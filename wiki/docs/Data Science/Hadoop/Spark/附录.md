---
title: 附录
toc: false
date: 2017-10-30
---     

### 1 安装Spark集群

在[官网](http://spark.apache.org/downloads.html)下载对应版本Spark源码以后，进行编译(详细参见[官网](http://spark.apache.org/docs/2.3.4/building-spark.html))

```bash
export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"
./dev/make-distribution.sh --name spark-2.3.4  --tgz  -Pyarn -Phadoop-2.7,hadoop-provided -Dhadoop.version=2.7.7 -Phive -Phive-thriftserver -Pyarn -Pflume -Pkafka-0-8 -Pparquet-provided,orc-provided
```

在`/etc/profile`中添加`export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native`使用Hadoop native。

接下来编辑配置文件`conf/spark-env.sh`和`conf/slaves`。

```text tab="spark-env.sh"
export JAVA_HOME=/opt/jdk1.8.0_201
export HADOOP_HOME=/opt/hadoop-2.7.7
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
SAPRK_MASTER_IP=centos1
SPARK_DRIVER_MEMORY=1G
export SPARK_DIST_CLASSPATH=$(/opt/hadoop-2.7.7/bin/hadoop classpath)
```

```text tab="slaves"
centos1
centos2
centos3
centos4
```

将配置好的spark发送给其他slaves之后，就可以用命令`sbin/start-all.sh`启动spark集群。 如果要查看spark管理界面，在浏览器中输入[http://centos1:8080](http://centos1:8080)


#### Livy

[Livy](https://github.com/cloudera/livy)是一个开源的与Apache Spark交互的REST接口。下载，编译Livy

```bash
git clone https://github.com/cloudera/livy.git
cd livy
mvn package
```

随后配置`livy.conf`参数

```
#livy服务端口
livy.server.port = 8998
#spark程序部署使用yarn集群或local
livy.spark.master = yarn/local
#spark 程序使用客户端模式
livy.spark.deploy-mode =client
```

最后使用命令`./bin/livy-server`启动。


